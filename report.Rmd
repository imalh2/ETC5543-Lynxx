---
title: "Report"
author: "Ibrahim Al-Hindi"
date: "`r Sys.Date()`"
output:
  bookdown::html_document2
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = FALSE, message = FALSE, warning = FALSE)
```

```{r libraries}
library(tidyverse)
library(here)
library(lubridate)
library(leaflet)
library(hms)
library(janitor)
library(broom)
library(kableExtra)
library(scales)
```

```{r data}
# Holidays dates
holidays_raw <- read_csv(here("data/addinsight/addinsight_prod.btspecialdays.csv.csv"))

# Links information
links_raw <- read_csv(here("data/AddInsight/addinsight_prod.btlinks.csv.csv"))

# List of links on South Rd and their geometries
southrd_links_raw <- read_csv(here("data/South-Rd/BT Links - South Rd.csv"))

# List of links on Marion Rd and their geometries
marionrd_links_raw <- read_csv(here("data/Marion-Rd/Marion Rd Links.csv"))

# Stops information
full_stops_raw <- read_csv(here("data/GTFS/stops.csv"))

# Routes, trips, and stops on South Rd
southrd_routes_stops_raw <- read_csv(here("data/South-Rd/South Rd Routes and Trips gtfs 1157.csv"))

# Routes, trips, and stops on Marion Rd
marionrd_routes_stops_raw <- read_csv(here("data/Marion-Rd/Marion Rd Routes Stops.csv"))

# GTFS-R Trip Updates for South Rd
southrd_updates_raw <- read_csv(here("data/South-Rd/trip_updates_SouthRd_Mar.csv"))

# GTFS-R Trip Updates for Marion Rd
marionrd_updates_raw <- read_csv(here("data/Marion-Rd/trip_updates_MarionRd_Mar.csv"))

# South Rd link statistics
southrd_link_stats_raw <- read_csv(here("data/South-Rd/link_stats_Mar.csv"))

# Marion Rd link statistics
marionrd_link_stats_raw <- read_csv(here("data/Marion-Rd/link_stats_Mar.csv"))
```

# Abstract

# Background

Adelaide's population increased from 1.1 million to 1.3 million residents between 2006 and 2016, with 66 million more kilometers traveled on the road network during that time. Infrastructure Australia paints a dire picture of the level of road congestion in Adelaide and its continued worsening in the coming years in line with both an increasing population and an increasing reliance on public transport in comparison to cars. The report estimated the annualized cost of road congestion for Greater Adelaide to be approximately \$1.4 billion in 2016 and is projected to rise to \$2.6 billion in 2031 (Infrastructure Australia, 2019).

With this backdrop in mind, the client (the South Australia Department for Infrastructure and Transport (DIT)) has in its possession an untapped wealth of data relating to traffic information collected through Bluetooth probes, which take count of passing motor vehicles in a particular time and location, therefore producing a metric for road congestion.

This data will be examined in conjunction with publicly available, historical real time bus trip updates collected by General Transit Feed Specification Realtime (GTFSr), which provides the arrival time for each stop on a bus's trip. The analysis aims to identify the relationship and robustness of bus travel times to road congestion on road segments of interest.

# Objectives

The aim of the proposed analysis is to investigate the extent of the relationship between bus travel times and road congestion - as measured by motor vehicle travel times - on identified road segments, where a strong relationship indicates a road segment where the bus travel times are less robust to congestion.

Initially, the bus performance metric to be used and applied was the average delay experienced by a bus trip on the segment of interest, as measured by a stop's predicted arrival time versus the scheduled arrival time. However, this was later revised to measuring the bus travel time between the first and last stops of a segment, removing the possibility that we are measuring how accurately the schedule predicts and/or buffers for congestion. The road congestion metric used is the average travel time of the vehicles across the segment.

A proposal outlining the analysis, the objectives, and the methodology was created and sent to the client, this was followed by a discussion with the client to provide more information regarding the analysis and clarify any points raised by the client. Ultimately, an agreement was reached for the analysis to fulfill the following objectives:

1.  Detailed travel time or congestion analysis comparing public transport response to road traffic on selected sections of road over a given period of time

2.  Repeatable methodology, code, functions, and visuals that produce detailed analysis on other segments of interest

In fulfilling the first objective, the segments of road analysed are South Road and Marion Road in Adelaide. This report uses the former to illustrate the methodology, while the latter is used for comparison. The period of time chosen is March 2022.

Regarding the second objective, the methodology and the code created aim to ensure the requirement of as little manual input and edits as possible when applied to different road segments.

The analysis undertaken in this report will form the basis of future analysis into:

-   additional road segments of interest to generate a ranking of bus network robustness which can help inform the allocation of resources

-   analysing the factors that can effect bus travel times such as the use of bus lanes, number of bus stops, traffic lights, etc.

-   creating a model predicting bus travel times using identified features.

# Data Sources, Description, and Wrangling

Three main data sources are used: DIT Addinsight, GTFS, and GTFSR. These data sources and their associated sub-sources will be outlined below. All the data is stored in the cloud using Amazon Web Services (AWS) and is accessed through Athena which uses regular SQL syntax.

The data cleaning and wrangling will be discussed as it was the part of the analysis that required the highest workload.

As mentioned above, the methodology will be illustrated on South Road, which is one of Adelaide's most important and major roads, and regularly suffers from congestion (Infrastructure Australia, 2019).

```{r, fig.cap="South Rd on map. Source: Google Maps"}
knitr::include_graphics("images/SouthRd_Map.png")
```

## DIT Addinsight

Traffic information collected by DIT. This is done through the use of Bluetooth devices that tag a Bluetooth-equipped vehicle when it comes into its range. The location of a Bluetooth device is called a site, and a link is a segment of road between two sites, an origin site and a destination site. This allows for the calculation of metrics such as the time taken to travel the link, among others.

The DIT Addinsight database is very large and contains many tables, each recording its own set of information, with foreign keys connecting most tables. This analysis uses only a subset of the tables in the database, presented below.

### Holidays

This dataset contains holidays dates, which is the only variable used.

```{r}
holidays <- unique(holidays_raw$date)

rm(holidays_raw)
```

### Links

#### All Links

This dataset lists all the links present in the network, not just the segments of interest. A link is a one-way section of road between two adjacent sites. Addinsight will measure statistics for every link in real time. The variables present and used from this dataset are

```{r links-desc}
links_raw %>%
  select(dms_update_ts:name, originid:length, direction) %>%
  names() %>% 
  as_tibble_col("Variable")  %>% 
  mutate(Description = c("Database update datetime",
                         "Unique link identifier",
                         "Description of link",
                         "The Bluetooth site ID that begins the link",
                         "The Bluetooth site ID that ends the link", 
                         "Boolean. Disabled links do not generate statistics",
                         "The link length in metres",
                         "Link direction of travel")) %>% 
  kable(caption = "Links data description") %>% 
  kable_styling(full_width = FALSE)
```

#### Segment Links

These are the links that present on the road segment examined only. These links were identified by inserting all the links into an interactive map in Tableau, and then manually selecting the area of interest on the map, which produces a list of the links in the highlighted area, and the geometry for each link. It is important to note that the some links can overlap with other links on the segment.

```{r segment-links-desc}
southrd_links_raw %>% 
  rename_with(tolower) %>% 
  select(-length, -name) %>% 
  names() %>% 
  as_tibble_col("Variable") %>% 
  mutate(Description = c("Unique link identifier",
                         "Order of geometry coordinates",
                         "Latitude",
                         "Longitude")) %>% 
  kable(caption = "Segment links data description") %>% 
  kable_styling(full_width = FALSE)
```

The links data was limited to the end of the period examined, in this case the end of March 2022. The data was filtered to the most recent update per link. This is done to obtain the most recent enabled status of each link. The two links datasets were joined together to create a single dataset which contains the links on the segment and all their related information. Finally, the `name` variable was used to created two additional variables, `start_loc` and `end_loc` which give the name of the link start location and end location, respectively. These variables will be used to identify the sequence of non-overlapping links on the segment later.

```{r}
# Limit updates to end of period examined and get most recent update per link,
# this is done to get the most recent enabled status for each link
links <- links_raw %>%
  filter(date(dms_update_ts) < "2022-04-01") %>%
  group_by(id) %>%
  filter(dms_update_ts == max(dms_update_ts)) %>%
  ungroup() %>%
  select(id, originid:length, direction) %>%
  distinct()

links_segment <- southrd_links_raw %>%
  rename_with(tolower) %>%
  mutate(
    latitude = round(latitude, 5),
    longitude = round(longitude, 5),
    # Extract name of locations where link starts and ends
    start_loc = str_extract(name, "(?<=- ).*(?= to)"),
    end_loc = str_extract(name, "(?<=to ).*")) %>%
  # Length in southrd_links_raw is not correct, join with links to get correct lengths and direction
  select(-length) %>%
  left_join(links, by = c("linkid" = "id"))

# Get only first entry per link
links_segment_unq <- links_segment %>%
  arrange(linkid, ordernumber) %>%
  distinct(linkid, .keep_all = TRUE)

directions <- sort(unique(links_segment_unq$direction))

rm(links_raw)
rm(southrd_links_raw)
```

### Links Statistics

These are the aggregated five minute statistics generated for each link.

```{r link-stats-desc}
southrd_link_stats_raw %>%
  select(logtime:tt) %>% 
  names() %>% 
  as_tibble_col("Variable") %>% 
  mutate(Description = c("Current interval timestamp",
                         "Unique link identifier",
                         "Travel time in seconds")) %>% 
  kable(caption = "Links statistics data description") %>% 
  kable_styling(full_width = FALSE)
```

The identification of the links on the segment and the data wrangling of the statistics will be discussed later in the report.

## General Transit Feed Specification (GTFS)

This is a common format developed by Google and used by public transport agencies around the world and contains static or scheduled information about public transport services such as routes, stops, schedule and geographic transit information. For the purposes of this analysis, only the bus routes and bus stops datasets will be used.

### Routes

These are the bus routes that go through South Road. These were identified by overlaying all the network routes on a map in Tableau and the routes on South Road were highlighted and exported to a list. The dataset contains simply the unique collection of route_id on the segment.

```{r}
segment_route_stops <- clean_names(southrd_routes_stops_raw)
  
segment_routes <- segment_route_stops %>% 
  pull(route_id) %>% 
  unique()
```

### Stops

The list of bus stops on the segment were identified in the same fashion as when identifying the routes. This produces a list of the stop_id's on the segment.

A dataset containing all the stops in the bus network and information relating to each stop is used and filtered to only the stops present on the segment (for the purposes of this report, the file containing all the stops on the network was pre-filtered to the stops on the segment only to accommodate Github file size limits. However, the code and methodology contained here apply as if the complete dataset were used and filtered through the code).

```{r}
segment_stops <- segment_route_stops %>% 
  pull(stop_id_gtfs_history_prod_stops_csv) %>% 
  unique()

# Join stops information to stops on the segment
stops_segment <- full_stops_raw %>%
  filter(stop_id %in% segment_stops) %>%
  select(stop_id, stop_name, stop_desc, stop_lat, stop_lon) %>%
  distinct(stop_id, .keep_all = TRUE) %>%
  # If stop is on East side, that means trip SB, and vice versa
  mutate(direction = if_else(str_detect(stop_name, "East"), "SB", "NB"))

rm(southrd_routes_stops_raw)
```

```{r, stops-desc}
stops_segment %>% 
  names() %>% 
  as_tibble_col("Variable") %>% 
  mutate(Description = c("Unique stop identifier",
                         "Name of the location. Uses a name that people will understand",
                         "Address of the stop",
                         "Latitude of the stop",
                         "Longitude of the stop",
                         "Road direction of the stop")) %>% 
  kable(caption = "Stops data description") %>% 
  kable_styling(full_width = FALSE)
```

The `direction` variable is manually created. In this case, if the stop is on the east side of South Road, then it is southbound (SB) away from the city; if the stop is on the west side of South Road, this it is northbound (NB) towards the city.

The bus stops will be plotted on a map to confirm they are all, in fact, on South Road.

```{r, fig.cap="Bus stops on South Road"}
# Plot on map to check the stops are all on South Rd
stops_segment %>%
    leaflet() %>% 
    addTiles() %>% 
    addCircles(lat = ~stop_lat, lng = ~stop_lon, label = ~ stop_id)
```

## General Transit Feed Specification Realtime (GTFSR)

Unlike GTFS which provides static information, GTFSR provides real time information consisting of two types. The first type is a trip's real time updates regarding a bus stop's expected arrival times and delays. The second type is a real time update of a bus's geographic position and speed at a specific point in time. This analysis uses the former only.

### Trip Updates

```{r}
# Keep only updates for stops on segment and remove weekends and public holidays
updates <- southrd_updates_raw %>%
  rename(
    trip_id = id,
    vehicle_id = label) %>%
  mutate(
    start_date = ymd(start_date),
    timestamp = as_datetime(timestamp, tz = "Australia/Adelaide"),
    arrival_time = as_datetime(arrival_time, tz = "Australia/Adelaide")) %>%
  select(-direction_id, -wheelchair_accessible) 
```

Once the bus routes that go through the segment were identified as outlined above, the real time updates for all the trips in March 2022 according to the routes were retrieved from the AWS database using Athena. This dataset is used to derive the bus travel time through the segment, which is the first element in the relationship being assessed in this analysis, with the other being the vehicles travel time as a measure of congestion. The SQL query to retrieve the updates can be found in appendix \@ref(trip-updates-sql-query)

First, the unedited data will be described.

```{r}
updates %>% 
  names() %>% 
  as_tibble_col("Variable") %>% 
  mutate(Description = c("Unique route identifier",
                         "Start date of the trip",
                         "Unique vehicle identifier",
                         "Timestamp of the real time update",
                         "Unique trip identifier",
                         "Order of stops for a particular trip",
                         "Unique stop identifier",
                         "The current schedule deviation for the trip. 
                         The delay (in seconds) can be positive (meaning that the vehicle is late) 
                         or negative (meaning that the vehicle is ahead of schedule)", 
                         "Predicted arrival time for a stop on a particular trip")) %>% 
  kable(caption = "Unedited updates data description") %>% 
  kable_styling(full_width = FALSE)
```

It is important to note the following:

-   One `route_id` can have many `trip_id`s

-   One `trip_id` occurs a maximum of one time a day, the `trip_id` can occur on multiple days

As a bus trip is occurring, at a certain timestamp a real time prediction of the arrival times of the remaining stops on the trip are updated.

Cleaning and wrangling this dataset proved to be the most challenging and time consuming section of this analysis, with many methodologies, cleaning iterations, and code trialed to arrive at the optimal treatment. This is due to the complex relationships between the observations in the dataset, and the variety of errors and inconsistencies encountered.

The following preliminary adjustments were done:

1. As each stop on a given trip can have multiple arrival time predictions with each update timestamp prior to reaching that stop, the SQL query insures that each stop only has the predicted arrival time corresponding to the latest timestamp, given that the later the prediction, the more accurate it is.

2. As a trip can begin and end outside the bounds of the segment, the updates were constrained only to those stops within the segment, in either direction.

3. Weekends and holidays were removed as we are interested in the relationships during working days.

```{r}
updates <- updates %>%
  inner_join(select(stops_segment, stop_id, direction), by = "stop_id") %>%
  filter(
    !start_date %in% holidays,
    !wday(start_date, label = TRUE) %in% c("Sat", "Sun"))
```

A new variable `to_stop_time` was created. This variable measures the time taken to reach each stop from the prior stop in seconds, within each trip. The variable was created to facilitate a potential deeper understanding of the data, to highlight any errors, and for potential utilities in the future such as drilling down to examine the pattern on a stop-basis.

Through this variable, a range of errors were discovered that needed to be amended. This is how the data appears before any remedial actions are taken.

```{r unedited-to-stops, fig.cap="Unedited to-stop times contain negative values"}
updates_stop_times <- updates %>%
  group_by(start_date, trip_id) %>%
  arrange(stop_sequence, .by_group = TRUE) %>%
  mutate(to_stop_time = as.numeric(arrival_time - lag(arrival_time), units = "secs")) %>%
  ungroup() %>%
  mutate(to_stop_time = replace_na(to_stop_time, 0))

ggplot(updates_stop_times, aes(to_stop_time, delay)) +
  geom_point() +
  geom_vline(xintercept = 0, color = "red", linetype = "dashed") +
  scale_x_continuous(labels = label_comma()) +
  scale_y_continuous(labels = label_comma()) +
  labs(x = "To-Stop Time (Seconds)", y = "Delay (Seconds)", title = "Unedited Trip To-Stop Time Vs. Delay") +
  theme_bw()
```

Figure \@ref(fig:unedited-to-stops) shows that `to_stop_time` contains negative values to the left of the red line, this is a clear error as it is not possible for time taken to reach a stop to be negative. Additionally we can see very high delay values in clusters, above 4,000 seconds, which is over an hour long.

In total, there were eight types of errors identified in the data. The list of errors, an example of each error, and the code to rectify the errors can be found in appendix \@ref(updates-errors).

```{r}
# Clean updates and get time to each stop for error detection
updates_stop_times <- updates %>%
  group_by(start_date, trip_id) %>%
  arrange(stop_sequence, .by_group = TRUE) %>%
  # Remove trips where all the stops have a delay over 2400 (40 minutes) or
  # early by more than 900 (15 minutes), ie entire trip is delayed or early.
  # Most likely error due to entering the information later. This is done to prevent
  # incorrect analysis since they will be in the wrong time period
  filter(!(all(delay > 2400) |
           all(delay < -900))) %>%
  # Remove one-off large jumps in between two observations
  filter(!(delay - lag(delay, order_by = stop_sequence, default = 0) > 1000 &
             delay - lead(delay, order_by = stop_sequence, default = 0) > 1000)) %>%
  # Remove any observations that have an arrival_time later than any following
  # arrival_time in the trip AND the timestamp is earlier than any following timestamps in the trip.
  # This ensures the most recent timestamp is preferred when discrepancy occurs
  filter(!(as.numeric(arrival_time) > order_by(-stop_sequence, cummin(as.numeric(arrival_time))) &
             as.numeric(timestamp) == order_by(-stop_sequence, cummin(as.numeric(timestamp))))) %>%
  # Remove if the arrival_time is less than the previous arrival_times AND the timestamp
  # is older than the previous timestamps
  filter(!(arrival_time < order_by(stop_sequence, cummax(as.numeric(arrival_time))) &
             timestamp < order_by(stop_sequence, cummax(as.numeric(timestamp))))) %>%
  # If arrival_time of a stop is less than prior stops but they all have the same
  # timestamp, it's not possible to know which is correct. Assume earlier stop_sequence
  # is correct since it is closer when the update is made
  filter(!(timestamp == order_by(stop_sequence, cummax(as.numeric(timestamp))) &
             arrival_time < order_by(stop_sequence, cummax(as.numeric(arrival_time))))) %>%
  # If after the above, two consecutive stops have the same arrival_time, remove
  # the one with an older timestamp
  filter(!(arrival_time == lead(arrival_time,
                                order_by = stop_sequence,
                                default = ymd("9999-01-01")) &
             timestamp < lead(timestamp,
                              order_by = stop_sequence,
                              default = ymd("9999-01-01")))) %>%
  # If two stops have the same arrival_time and same time_stamp, remove the one
  # with a higher stop sequence. Make sure only 2 stops and not more
  filter(!(arrival_time != lead(arrival_time,
                                order_by = stop_sequence,
                                default = ymd("9999-01-01")) &
             arrival_time == lag(arrival_time,
                                 order_by = stop_sequence,
                                 default = ymd("0000-01-01")) &
             timestamp == lag(timestamp,
                              order_by = stop_sequence,
                              default = ymd("0000-01-01")))) %>%
  # Remove trips with multiple repeating arrival_times
  filter(!n_distinct(arrival_time) < n()) %>%
  mutate(
    to_stop_time = as.numeric(arrival_time - lag(arrival_time), units = "secs"),
    first_stop = first(stop_id, order_by = stop_sequence),
    last_stop = last(stop_id, order_by = stop_sequence)) %>%
  ungroup() %>%
  mutate(to_stop_time = replace_na(to_stop_time, 0))

error_percentage <- round((nrow(updates) - nrow(updates_stop_times)) / nrow(updates) * 100, 2)
```

Great effort was put into identifying each type of error and remedying it in a way that does not produce further errors, or that removes large amounts of data, identifying the correct order of the types of errors to be tackled was also essential. In addition, formulating the code to fix each error required various trial and error iterations. This was all done to ensure the errors were removed as surgically as possible to minimize data loss and due to the sensitive nature of the relationships between the stops on each trip.

The percentage of error entries located and fixed in the data was `r error_percentage`%. The cleaned data now appears as follows:

```{r cleaned-to-stops, fig.cap="Cleaned to-stop times do not contain negative values"}
ggplot(updates_stop_times, aes(to_stop_time, delay)) +
  geom_point() +
  geom_vline(xintercept = 0, color = "red", linetype = "dashed") +
  scale_x_continuous(labels = label_comma()) +
  scale_y_continuous(labels = label_comma()) +
  labs(x = "To-Stop Time (Seconds)", y = "Delay (Seconds)", title = "Cleaned Trip To-Stop Time Vs. Delay") +
  theme_bw()
```

With the data now cleaned, two additional variables were created called `first_stop` and `last_stop`, which identify the first and last stops of each trip within the segment. The total time per trip can now be derived by calculating the time between the first stop and last stop of the trip within the segment. The arrival time of the first stop and last stop on the segment will be regarded as the start and end time, respectively, of the trip. The distribution of the trip times per direction is shown below. The two most occurring first-last stops pair per direction will be used.

```{r two-stops-pairs, fig.cap="Different stops pairs in the same direction have different trip times"}
# Take top occurring stops pair for each direction
top_first_last_stops <- updates_stop_times %>%
  distinct(start_date, trip_id, direction, first_stop, last_stop) %>%
  group_by(direction) %>%
  count(first_stop, last_stop, sort = TRUE) %>%
  slice_max(order_by = n, n =2) %>%
  ungroup()

# Get trips with only most occurring stops pair per direction identified
updates_stop_times_x <- updates_stop_times %>%
  semi_join(top_first_last_stops, by = c("direction", "first_stop", "last_stop"))

updates_trip_time <- updates_stop_times_x %>%
  group_by(start_date, trip_id) %>%
  arrange(stop_sequence, .by_group = TRUE) %>%
  mutate(trip_time = as.numeric((last(arrival_time) -first(arrival_time)), units = "secs"),
         delay_diff = abs(last(delay) - first(delay))) %>%
  filter(stop_sequence == first(stop_sequence, order_by = stop_sequence)) %>%
  ungroup() %>%
  distinct(start_date, trip_id, .keep_all = TRUE) %>% 
  mutate(stops_pair = paste0(first_stop, "-", last_stop))

ggplot(updates_trip_time, aes(trip_time, fill = stops_pair)) +
  geom_density(alpha = 0.5) +
  scale_x_continuous(labels = label_comma()) +
  labs(x = "Trip Time (Seconds)",
       y = "",
       fill = "First-Last Stops",
       title = "Trip Time Distribution per Stops Pair per Direction") +
  facet_wrap(vars(direction), scales = "free_x") +
  theme_bw() +
  theme(axis.text.y = element_blank(),
        axis.ticks.y = element_blank())
```

As figure \@ref(fig:two-stops-pairs) shows, different first-last stops pairs in the same direction have different travel times. This means that different routes and trips can have different travel times solely based on their respective first and last stops on the segment, this renders the travel time between them incomparable as they occupy different distances. Therefore, only trips with the same pair of first and last stops within the segment will be kept, with the remaining trips discarded; there can be only one pair of first and last stops per direction, so that the distance is constant for the all the trips and the time is therefore comparable.

This pair of stops is identified as the most occurring pair per direction. Now, only trips with this pair of first and last stops are kept in the data.

The distribution of the trip times per direction is shown below.

```{r large-trip-times, fig.cap="Excessively large trip times exist, especially southbound"}
top_first_last_stops <- updates_stop_times %>%
  distinct(start_date, trip_id, direction, first_stop, last_stop) %>%
  group_by(direction) %>%
  count(first_stop, last_stop, sort = TRUE) %>%
  slice_max(order_by = n) %>%
  ungroup()

updates_stop_times <- updates_stop_times %>%
  semi_join(top_first_last_stops, by = c("direction", "first_stop", "last_stop"))

updates_trip_time <- updates_stop_times %>%
  group_by(start_date, trip_id) %>%
  arrange(stop_sequence, .by_group = TRUE) %>%
  mutate(
    trip_time = as.numeric((last(arrival_time) -first(arrival_time)), units = "secs"),
    delay_diff = abs(last(delay) - first(delay))) %>%
  ungroup()

ggplot(updates_trip_time, aes(trip_time)) +
  geom_histogram() +
  labs(x = "Trip Time (Seconds)", title = "Trip Time Distribution per Direction") +
  scale_x_continuous(labels = label_comma()) +
  scale_y_continuous(labels = label_comma()) +
  facet_wrap(vars(direction)) +
  theme_bw()
```

As figure \@ref(fig:large-trip-times) shows, excessive trip times occur, especially southbound. It is difficult to determine whether these are errors or genuine trip times without using further information. A variable called `delay_diff` is created which calculates the size of the difference between the delay of the first stop and the delay of the last stop per trip. Excessive values of this variable indicates the large travel time is due to an error as either of the stops has an artificially large delay or early arrival. A plot of `delay_diff` vs `travel_time` is shown below.

```{r delay-diff, fig.cap="Size of difference between first and last stop delays. Southbound is more problematic"}
# One row per trip corresponding to highest delay in the trip. For error detection using plots
trip_time_delay <- updates_trip_time %>%
  group_by(start_date, trip_id) %>%
  filter(abs(delay) == max(abs(delay))) %>%
  ungroup() %>%
  distinct(start_date, trip_id, .keep_all = TRUE)

ggplot(trip_time_delay, aes(delay_diff, color = direction)) +
  geom_boxplot() +
  labs(x = "Delay Difference (Seconds)",
       color = "Direction",
       title = "Size of Difference between Delays of First and Last Stops") +
  scale_x_continuous(labels = label_comma()) +
  theme_bw() +
  theme(axis.text.y = element_blank(),
        axis.ticks.y = element_blank())
```

Based on figure \@ref(fig:large-trip-times), trips with a `delay_diff` greater than 600 (10 minutes) were removed as they were most likely errors. The resulting data now appears as follows:

```{r trip-times, fig.cap="Excessively large trip times no longer exist"}
updates_trip_time <- updates_trip_time %>%
  # If the delay_diff is greater than 600 (10 minutes), most likely an error
  filter(delay_diff < 600) %>%
  arrange(start_date, trip_id, stop_sequence)

trip_times <- updates_trip_time %>%
  group_by(start_date, trip_id) %>%
  filter(stop_sequence == first(stop_sequence, order_by = stop_sequence)) %>%
  ungroup() %>%
  distinct(start_date, trip_id, .keep_all = TRUE) %>% 
  select(-delay_diff)

rm(southrd_updates_raw)

ggplot(trip_times, aes(trip_time)) +
  geom_histogram() +
  labs(x = "Trip Time (Seconds)", title = "Trip Time Distribution per Direction") +
  scale_x_continuous(labels = label_comma()) +
  scale_y_continuous(labels = label_comma()) +
  facet_wrap(vars(direction)) +
  theme_bw()
```

The data relating to only the first stop per trip was kept since the arrival time of the first stop will be considered as the trip start time used as the basis for aggregation later in the analysis.

The final form of the bus trip times dataset is as follows:

```{r}
trip_times %>% 
  names() %>% 
  as_tibble_col("Variable") %>% 
  mutate(Description = c("Unique route identifier",
                         "Start date of the trip",
                         "Unique vehicle identifier",
                         "Timestamp of the real time update",
                         "Unique trip identifier",
                         "Order of stops for a particular trip",
                         "Unique stop identifier",
                         "The current schedule deviation for the trip. 
                         The delay (in seconds) can be positive (meaning that the vehicle is late) 
                         or negative (meaning that the vehicle is ahead of schedule)", 
                         "Predicted arrival time for a stop on a particular trip",
                         "Direction of the trip",
                         "Time (in seconds) to reach the current stop from the previou stop",
                         "First stop of the trip in the segment",
                         "Last stop of the trip in the segment",
                         "Total trip time (in seconds)")) %>% 
  kable(caption = "Bus trip times data description") %>% 
  kable_styling(full_width = FALSE)
```


























# Appendix

## Trip Updates SQL Query

![](images/updates_SQL.png)

## Updates Errors

1. All stops for the trip have very large, or very small, similar delays. This means that the entire trip is very delayed or very early. This is most likely due to retrospectively entering the information at a later time. By examining \@ref(fig:unedited-to-stops), the threshold was set at 2400 seconds (40 minutes) delay and 900 seconds (15 minutes) early. These trips were removed to prevent incorrect analysis since they will be in the wrong time period

![](images/all_large_delays.png)

These trips were removed as they will be in the wrong timeframe when analyzing against the vehicle travel time.

2. A stop has a sudden large predicted delay resulting in a much larger arrival time than that of the following stop. These stops were removed

![](images/suddent_large_delay.png)

3. A stop has an arrival time later than any following stops and the timestamp is earlier than any following stops. These stops were removed to ensure the most recent timestamp is preferred when discrepancy occurs

![](images/arrive_later_stamp_earlier.png)

4. A stop's arrival time is earlier than previous stops and the timestamp is older

![](images/arrive_earlier_stamp_older.png)

5. A stop's arrival time is earlier than prior stops but they both have the same timestamp. In this case it is not possible to know which is correct. We assume the stop with the earlier stop sequence is correct since it is closer to the bus when the update is made

![](images/same_timestamp_still_error.png)

6. Two consecutive stops have identical arrival times but with different timestamps. The stop with the older timestamp was removed

![](images/same_arrival_different_stamps.png)

7. Two consecutive stops have identical arrival times and timestamps. Remove the stop with a higher stop sequence

![](images/same_arrival_same_stamp.png)

8. Many stops on the same trip have the same arrival time likely due to retrospective entry error. These trips were removed

The code to fix the errors is displayed here

```{r, echo=TRUE, eval=FALSE}
# Clean updates and get time to each stop for error detection
updates_stop_times <- updates %>%
  group_by(start_date, trip_id) %>%
  arrange(stop_sequence, .by_group = TRUE) %>%
  # Remove trips where all the stops have a delay over 2400 (40 minutes) or
  # early by more than 900 (15 minutes), ie entire trip is delayed or early.
  # Most likely error due to entering the information later. This is done to prevent
  # incorrect analysis since they will be in the wrong time period
  filter(!(all(delay > 2400) |
           all(delay < -900))) %>%
  # Remove one-off large jumps in between two observations
  filter(!(delay - lag(delay, order_by = stop_sequence, default = 0) > 1000 &
             delay - lead(delay, order_by = stop_sequence, default = 0) > 1000)) %>%
  # Remove any observations that have an arrival_time later than any following
  # arrival_time in the trip AND the timestamp is earlier than any following timestamps in the trip.
  # This ensures the most recent timestamp is preferred when discrepancy occurs
  filter(!(as.numeric(arrival_time) > order_by(-stop_sequence, cummin(as.numeric(arrival_time))) &
             as.numeric(timestamp) == order_by(-stop_sequence, cummin(as.numeric(timestamp))))) %>%
  # Remove if the arrival_time is less than the previous arrival_times AND the timestamp
  # is older than the previous timestamps
  filter(!(arrival_time < order_by(stop_sequence, cummax(as.numeric(arrival_time))) &
             timestamp < order_by(stop_sequence, cummax(as.numeric(timestamp))))) %>%
  # If arrival_time of a stop is less than prior stops but they all have the same
  # timestamp, it's not possible to know which is correct. Assume earlier stop_sequence
  # is correct since it is closer when the update is made
  filter(!(timestamp == order_by(stop_sequence, cummax(as.numeric(timestamp))) &
             arrival_time < order_by(stop_sequence, cummax(as.numeric(arrival_time))))) %>%
  # If after the above, two consecutive stops have the same arrival_time, remove
  # the one with an older timestamp
  filter(!(arrival_time == lead(arrival_time,
                                order_by = stop_sequence,
                                default = ymd("9999-01-01")) &
             timestamp < lead(timestamp,
                              order_by = stop_sequence,
                              default = ymd("9999-01-01")))) %>%
  # If two stops have the same arrival_time and same time_stamp, remove the one
  # with a higher stop sequence. Make sure only 2 stops and not more
  filter(!(arrival_time != lead(arrival_time,
                                order_by = stop_sequence,
                                default = ymd("9999-01-01")) &
             arrival_time == lag(arrival_time,
                                 order_by = stop_sequence,
                                 default = ymd("0000-01-01")) &
             timestamp == lag(timestamp,
                              order_by = stop_sequence,
                              default = ymd("0000-01-01")))) %>%
  # Remove trips with multiple repeating arrival_times
  filter(!n_distinct(arrival_time) < n()) %>%
  mutate(
    to_stop_time = as.numeric(arrival_time - lag(arrival_time), units = "secs"),
    first_stop = first(stop_id, order_by = stop_sequence),
    last_stop = last(stop_id, order_by = stop_sequence)) %>%
  ungroup() %>%
  mutate(to_stop_time = replace_na(to_stop_time, 0))
```








# References

-   Infrastructure Australia (2019). Urban Transport Crowding and Congestion. The Australian Infrastructure Audit 2019 Supplementary report. Retrieved from <https://www.infrastructureaustralia.gov.au/sites/default/files/2019-08/Urban%20Transport%20Crowding%20and%20Congestion.pdf>
